# Lab: 17 - Web Scraping

## Web Scraping
## Lab17-Web-Scraping

## Author: Richard Whitehead

# Description

It’s wonderful when someone has gone to the effort to expose their site’s data through an API.

But not everyone can (or wants to) do that.

No problem. Let’s code up a web scraper that can automate the process of manually using the site.

Feature Tasks and Requirements: Scrape a Wikipedia page and record which passages need citations. E.g. History of Mexico has 7 “citation needed” cases, as of this writing. Your web scraper should report the number of citations needed. Your web scraper should identify those cases AND include the relevant passage. E.g. Citation needed for “lorem spam and impsum eggs” Consider the “relevant passage” to be the parent element that contains the passage, often a paragraph element.

Getting Started
Clone this repository to your local machine.

$ git clone [https://github.com/RichWhitehead/web-scraper]

To run the program from VS Code:

Select File -> Open -> Project/Solution

Next navigate to the location you cloned the Repository.

Double click on the web-scraper directory.

Then select and open scraper.py

